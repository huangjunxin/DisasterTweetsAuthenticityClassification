{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1 Importing the Pre-Processed Dataset\n",
    "\n",
    "As the dataset has been separated to 4 parts, we need to reread them from files:\n",
    "\n",
    "- X_train (training variables of the dataset)\n",
    "- X_val (validation variables of the dataset)\n",
    "- y_train (training labels of the dataset)\n",
    "- y_val (validation labels of the dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_val = pd.read_csv('X_val.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_val = pd.read_csv('y_val.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because we are only attempting to classify the ```True``` from the ```False``` by the text. Then we should select the variable \"text\" from X_train and X_val, and select the variable \"target\" from y_train and y_val."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_text = X_train['cleaned_text'].to_list()\n",
    "train_label = y_train['target'].to_list()\n",
    "val_text = X_val['cleaned_text'].to_list()\n",
    "val_label = y_val['target'].to_list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['  jimmyfallon crush squirrel bone mortar pestl school  bio dept  realli sure whi worstsummerjob',\n ' mccainenl think spectacular look stonewal riot obliter white house ',\n 'can t bloodi wait   soni set date stephen king       the dark tower    stephenk thedarktow    bdisgust',\n 'protest ralli stone mountain  atleast they r burn build loot store like individu  protest ',\n ' rbcinsur quot websit   disaster  tri 3 browser  amp  3 machines  alway get  miss info  error due non exist drop down ']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 1, 0, 0, 0]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 Training and Validating Classifier\n",
    "\n",
    "We will use the TfidfVectorizer to tokenize tweets and the SVC classifier from sklearn.svm for the task of classification.\n",
    "\n",
    "Thus, the pipeline would be:\n",
    "1. TfidfVectorizer\n",
    "2. SVC\n",
    "\n",
    "Before that, we should use the GridSearchCV classifier to perform an exhaustive search for some parameters of the TfidfVectorizer and SVC classes in order to find the ones that give the best results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best score: 0.8031198686371099\n",
      "Best parameters: {'svc__C': 1.5, 'tfidf__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([('tfidf', TfidfVectorizer(decode_error=\"ignore\")), ('svc', SVC(random_state=888))])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1,1), (1,2), (2,2)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__smooth_idf': (True, False),\n",
    "    'tfidf__sublinear_tf': (True, False),\n",
    "    'svc__C': (1.3, 1.5, 1.7),\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=3, cv=3)\n",
    "grid_result = grid.fit(train_text, train_label)\n",
    "\n",
    "print(\"Best score: \" + str(grid_result.best_score_))\n",
    "print(\"Best parameters: \" + str(grid_result.best_params_))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "According to the result above, we can apply the best parameters on final training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "SVC(C=1.5, random_state=888)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    decode_error=\"ignore\",\n",
    "    ngram_range=(1,2),\n",
    "    smooth_idf=False,\n",
    "    sublinear_tf=True,\n",
    "    use_idf=True\n",
    ")\n",
    "train_text_vectorized = tfidf_vectorizer.fit_transform(train_text)\n",
    "val_text_vectorized = tfidf_vectorizer.transform(val_text)\n",
    "\n",
    "model = SVC(random_state=888, C=1.5)\n",
    "model.fit(train_text_vectorized, train_label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then evaluate the prediction results:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       884\n",
      "           1       0.78      0.66      0.71       639\n",
      "\n",
      "    accuracy                           0.78      1523\n",
      "   macro avg       0.78      0.76      0.77      1523\n",
      "weighted avg       0.78      0.78      0.77      1523\n",
      "\n",
      "Mean accuracy 0.7774130006565988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_val_prediction = model.predict(val_text_vectorized)\n",
    "\n",
    "print(classification_report(val_label, y_val_prediction))\n",
    "model_score = model.score(val_text_vectorized, val_label)\n",
    "print(\"Mean accuracy \" + str(model_score))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
